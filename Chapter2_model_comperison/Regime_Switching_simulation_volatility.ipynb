{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b174be83-953a-4bbf-9d99-6e27ed66dd5c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import requests\n",
    "import io\n",
    "import zipfile\n",
    "from scipy.stats import norm\n",
    "\n",
    "import cvxpy as cp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a78ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_monthly_factor_returns_from_daily(daily_factors: pd.DataFrame, factor_cols=None):\n",
    "    \"\"\"\n",
    "    Input: simple daily returns (not log). Monthly return is multiplicative.\n",
    "    Output index = last *trading* day available in the data for each month\n",
    "    (so it matches weights/costs indexed by last trading day).\n",
    "    # TODO: in this simulation we have log so we need to change\n",
    "    \"\"\"\n",
    "    if factor_cols is None:\n",
    "        factor_cols = list(daily_factors.columns)\n",
    "\n",
    "    x = daily_factors[factor_cols].copy().dropna(how=\"all\")\n",
    "    month = x.index.to_period(\"M\")\n",
    "\n",
    "    monthly = (1.0 + x).groupby(month).prod() - 1.0\n",
    "\n",
    "    # index = last trading day in each month \n",
    "    assert x.index.is_monotonic_increasing\n",
    "    month_end_dates = x.groupby(month).tail(1).index\n",
    "    monthly.index = month_end_dates\n",
    "\n",
    "    return monthly.sort_index()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bcaa303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need daily and not monthly returns\n",
    "def daily_portfolio_returns_from_monthly_weights(daily_returns: pd.DataFrame,\n",
    "                                                 W_monthly: pd.DataFrame) -> pd.Series:\n",
    "\n",
    "    R = daily_returns.dropna(how=\"any\").copy()\n",
    "    month = R.index.to_period(\"M\")\n",
    "\n",
    "    W = W_monthly.copy()\n",
    "    W[\"m\"] = W.index.to_period(\"M\")\n",
    "    W = W.set_index(\"m\").sort_index()\n",
    "\n",
    "    out = []\n",
    "    months = sorted(month.unique())\n",
    "    for m_trade in months:\n",
    "        if m_trade not in W.index:\n",
    "            continue\n",
    "\n",
    "        w = W.loc[m_trade]\n",
    "        cols = [c for c in w.index if c in R.columns]\n",
    "        Rt = R.loc[month == m_trade, cols]\n",
    "        if Rt.empty:\n",
    "            continue\n",
    "\n",
    "        out.append(pd.Series(Rt.values @ w[cols].values, index=Rt.index))\n",
    "\n",
    "    return pd.concat(out).sort_index()\n",
    "\n",
    "\n",
    "def portfolio_stats_paper_style(returns,\n",
    "                                periods_per_year=252,\n",
    "                                rf_annual=0.0,\n",
    "                                target=0.0,\n",
    "                                alpha=0.95):\n",
    "\n",
    "    r = pd.Series(returns).dropna().astype(float).to_numpy()\n",
    "    if len(r) < 2:\n",
    "        raise ValueError(\"need at least 2 observations\")\n",
    "    if not (0.0 < alpha < 1.0):\n",
    "        raise ValueError(\"alpha must be in (0,1)\")\n",
    "\n",
    "    mu = float(np.mean(r))\n",
    "    sigma2 = float(np.var(r, ddof=0))\n",
    "    sigma = float(np.sqrt(sigma2))\n",
    "\n",
    "    mu_ann = mu * periods_per_year\n",
    "    sigma2_ann = sigma2 * periods_per_year\n",
    "    sigma_ann = float(np.sqrt(sigma2_ann))\n",
    "\n",
    "    downside = (r[r < target] - target)\n",
    "    semivar = 0.0 if downside.size == 0 else float(np.mean(downside**2))\n",
    "    semidev_ann = float(np.sqrt(semivar * periods_per_year))\n",
    "\n",
    "    # VaR/CVaR\n",
    "    q = 1.0 - alpha\n",
    "    VaR = float(np.quantile(r, q))\n",
    "    tail = r[r <= VaR]\n",
    "    CVaR = VaR if tail.size == 0 else float(np.mean(tail))\n",
    "\n",
    "    # drawdowns\n",
    "    wealth = np.concatenate([[1.0], np.cumprod(1.0 + r)])\n",
    "    peak = np.maximum.accumulate(wealth)\n",
    "    dd = 1.0 - wealth / peak\n",
    "    pos_dd = dd[dd > 0]\n",
    "    avg_dd = 0.0 if pos_dd.size == 0 else float(np.mean(pos_dd))\n",
    "\n",
    "    # excess mean (per-period rf from annual rf)\n",
    "    rf_per = (1.0 + rf_annual)**(1.0 / periods_per_year) - 1.0\n",
    "    excess_ann_mean = (mu - rf_per) * periods_per_year\n",
    "\n",
    "    sharpe = np.nan if sigma_ann == 0 else float(excess_ann_mean / sigma_ann)\n",
    "    sortino = np.nan if semidev_ann == 0 else float(excess_ann_mean / semidev_ann)\n",
    "\n",
    "    # tail-adjusted Sharpe (NO annualization of CVaR/mVaR)\n",
    "    ta_sharpe_cvar = np.nan if CVaR == 0 else float(excess_ann_mean / abs(CVaR))\n",
    "\n",
    "    # Cornish-Fisher modified VaR\n",
    "    if sigma == 0:\n",
    "        skew = 0.0\n",
    "        exkurt = 0.0\n",
    "    else:\n",
    "        xc = r - mu\n",
    "        m3 = float(np.mean(xc**3))\n",
    "        m4 = float(np.mean(xc**4))\n",
    "        skew = m3 / (sigma**3)\n",
    "        kurt = m4 / (sigma**4)\n",
    "        exkurt = kurt - 3.0\n",
    "\n",
    "    z = float(norm.ppf(q))\n",
    "    z_cf = (z\n",
    "            + (1/6)  * (z**2 - 1)   * skew\n",
    "            + (1/24) * (z**3 - 3*z) * exkurt\n",
    "            - (1/36) * (2*z**3 - 5*z) * (skew**2))\n",
    "\n",
    "    mVaR = float(mu + sigma * z_cf)\n",
    "    ta_sharpe_mvar = np.nan if mVaR == 0 else float(excess_ann_mean / abs(mVaR))\n",
    "\n",
    "    return {\n",
    "        \"Ann. Mean (%)\": 100 * mu_ann,\n",
    "        \"Ann. StdDev (%)\": 100 * sigma_ann,\n",
    "        \"Ann. SemiDev (%)\": 100 * semidev_ann,\n",
    "        \"CVaR 95% (%)\": 100 * CVaR,\n",
    "        \"Avg DD (%)\": 100 * avg_dd,\n",
    "        \"VaR 95% (%)\": 100 * VaR,\n",
    "        \"Sharpe (ann.)\": sharpe,\n",
    "        \"Sortino (ann.)\": sortino,\n",
    "        \"Tail-Adj Sharpe (CVaR95)\": ta_sharpe_cvar,\n",
    "        \"Tail-Adj Sharpe (mVaR95)\": ta_sharpe_mvar,\n",
    "    }\n",
    "\n",
    "\n",
    "def make_table_for_portfolios(portfolios: dict,\n",
    "                              periods_per_year=252,\n",
    "                              rf_annual=0.0,\n",
    "                              target=0.0,\n",
    "                              alpha=0.95) -> pd.DataFrame:\n",
    "    rows = [\n",
    "        \"Ann. Mean (%)\",\n",
    "        \"Ann. StdDev (%)\",\n",
    "        \"Ann. SemiDev (%)\",\n",
    "        \"CVaR 95% (%)\",\n",
    "        \"Avg DD (%)\",\n",
    "        \"VaR 95% (%)\",\n",
    "        \"Sharpe (ann.)\",\n",
    "        \"Sortino (ann.)\",\n",
    "        \"Tail-Adj Sharpe (CVaR95)\",\n",
    "        \"Tail-Adj Sharpe (mVaR95)\",\n",
    "    ]\n",
    "\n",
    "    out = pd.DataFrame(index=rows)\n",
    "    for name, r in portfolios.items():\n",
    "        st = portfolio_stats_paper_style(r, periods_per_year=periods_per_year,\n",
    "                                         rf_annual=rf_annual, target=target, alpha=alpha)\n",
    "        out[name] = [st[k] for k in rows]\n",
    "    return out\n",
    "\n",
    "def df_to_booktabs_latex(df: pd.DataFrame, caption=None, label=None) -> str:\n",
    "    latex = df.to_latex(\n",
    "        escape=True,\n",
    "        float_format=lambda x: f\"{x:.2f}\",\n",
    "        column_format=\"l\" + \"r\"*df.shape[1],\n",
    "        bold_rows=False\n",
    "    )\n",
    "    # convert to booktabs style\n",
    "    latex = latex.replace(\"\\\\toprule\", \"\\\\toprule\").replace(\"\\\\midrule\", \"\\\\midrule\").replace(\"\\\\bottomrule\", \"\\\\bottomrule\")\n",
    "    if caption or label:\n",
    "        # wrap in table environment if requested\n",
    "        body = latex\n",
    "        lines = [\"\\\\begin{table}[!htbp]\", \"\\\\centering\"]\n",
    "        if caption:\n",
    "            lines.append(f\"\\\\caption{{{caption}}}\")\n",
    "        if label:\n",
    "            lines.append(f\"\\\\label{{{label}}}\")\n",
    "        lines.append(body.strip())\n",
    "        lines.append(\"\\\\end{table}\")\n",
    "        latex = \"\\n\".join(lines)\n",
    "    return latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "351ec807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with turnover cost\n",
    "# do not do daily evaulation and cost. simple monthly!!\n",
    "def Markowitz_with_turnover_TC_diffobj(\n",
    "    daily_factors, factor_cols,\n",
    "    gamma=5.0, ridge=1e-8, nonneg=False,\n",
    "    market_vol_proxy=\"Mkt-rf\",\n",
    "    c_tc=0.0021, abs_eps=1e-10,\n",
    "    use_drift_turnover=True,              # TRUE = drift turnover (RL,Vol paper style); FALSE = no costs at all\n",
    "    bounded_b: bool = False\n",
    "                        ):\n",
    "\n",
    "    _printed = False\n",
    "\n",
    "    def _check_month_loss_once(monthly_F, rv2_aligned):\n",
    "        nonlocal _printed\n",
    "        if _printed:\n",
    "            return\n",
    "        _printed = True\n",
    "\n",
    "        months_all = monthly_F.index.to_period(\"M\")\n",
    "        months_valid = rv2_aligned[rv2_aligned.notna()].index.to_period(\"M\")\n",
    "\n",
    "        lost = pd.Index(months_all).difference(pd.Index(months_valid))\n",
    "\n",
    "\n",
    "    factor_cols = [c for c in factor_cols if c != market_vol_proxy] # for optimization (input to markowitz), safety\n",
    "\n",
    "    monthly_F = compute_monthly_factor_returns_from_daily(daily_factors, factor_cols=factor_cols) # monthly returns, do not include MKT-RF\n",
    "    m = daily_factors.dropna().index.to_period(\"M\")\n",
    "\n",
    "    # realized volatility on Mkt-rf, we ll use it for scaling\n",
    "    # If market_vol_proxy column doesn't exist (simulated data), create equal-weighted market index\n",
    "    if market_vol_proxy not in daily_factors.columns:\n",
    "        # Create equal-weighted market index from available assets\n",
    "        # effect?!!!!!!!!!!!\n",
    "        market_index = daily_factors[factor_cols].mean(axis=1)\n",
    "        daily_factors_with_mkt = daily_factors.copy()\n",
    "        daily_factors_with_mkt[market_vol_proxy] = market_index\n",
    "        mkt_col = market_vol_proxy# ....\n",
    "        rv = daily_factors_with_mkt[mkt_col].groupby(m).std(ddof=1)\n",
    "    else:\n",
    "        mkt_col = market_vol_proxy\n",
    "        rv = daily_factors[mkt_col].groupby(m).std(ddof=1)\n",
    "    \n",
    "    rv2 = rv.shift(1)  # use lagged volatility (no look-ahead)\n",
    "\n",
    "    #align lagged vol to monthly_F using MONTH PERIOD, then restore trading month-end dates \n",
    "    rv2 = rv2.reindex(monthly_F.index.to_period(\"M\")) # it\n",
    "    rv2.index = monthly_F.index\n",
    "    assert rv2.index.equals(monthly_F.index)\n",
    "\n",
    "\n",
    "    _check_month_loss_once(monthly_F, rv2)\n",
    "\n",
    "\n",
    "    # align and drop months where lagged vol is missing\n",
    "    valid = rv2.notna()\n",
    "    Rm = monthly_F.loc[valid]\n",
    "    s = rv2.loc[valid].to_numpy().reshape(-1, 1)# we need to reshape cause of the division part\n",
    "\n",
    "    R = Rm.to_numpy()  # (T x K)\n",
    "    K = R.shape[1]\n",
    "    T = R.shape[0]\n",
    "    s = np.maximum(s, 1e-12)  # safety\n",
    "    ### we use these above R,s inside the objective function and\n",
    "    def smooth_abs(x):\n",
    "        return np.sqrt(x*x + abs_eps)\n",
    "\n",
    "    def eta_to_theta(eta):\n",
    "        a = eta[:K]\n",
    "        b = eta[K:]\n",
    "        theta = a[None, :] + b[None, :] / s # already lagged\n",
    "        # Normalize to sum to 1\n",
    "        denom = np.sum(theta, axis=1, keepdims=True)\n",
    "        theta = theta / np.where(np.abs(denom) > 1e-12, denom, 1.0)\n",
    "        return theta\n",
    "\n",
    "    def taus_series(eta):\n",
    "        # TRUE = drift turnover (RL-style pre-trade drift turnover)\n",
    "        # FALSE = do not even calculate costs: if we do not calculate costs, we should stuck to long-short also\n",
    "        if not use_drift_turnover:\n",
    "            return np.zeros(R.shape[0], dtype=float)\n",
    "\n",
    "        theta = eta_to_theta(eta)\n",
    "        T = theta.shape[0]\n",
    "        taus = np.zeros(T, dtype=float)\n",
    "        if T <= 1:\n",
    "            return taus\n",
    "\n",
    "        for t in range(1, T):\n",
    "            # last month target (post-trade)\n",
    "            w_prev_post = theta[t-1]\n",
    "\n",
    "            # realized monthly returns during last month\n",
    "            R_prev = R[t-1]\n",
    "\n",
    "            # drift to pre-trade weights\n",
    "            g = 1.0 + R_prev\n",
    "            numer = w_prev_post * g\n",
    "            denom = float(np.sum(numer))\n",
    "            w_pre = numer / denom if abs(denom) > 1e-12 else w_prev_post\n",
    "\n",
    "            # trade to current target\n",
    "            w_target = theta[t]\n",
    "\n",
    "            # turnover\n",
    "            tau_t = 0.5 * float(np.sum(smooth_abs(w_target - w_pre)))\n",
    "            taus[t] = tau_t # save monthly costs--> use it for net retunrs, we do not multiply with c_tc here!\n",
    "            # later for cost calculation you need\n",
    "\n",
    "        return taus\n",
    "\n",
    "    def TC(eta):\n",
    "        # TRUE = drift turnover (RL-style pre-trade drift turnover)\n",
    "        # FALSE = do not even calculate costs: if we do not calculate costs, we should stuck to long-short also\n",
    "        if not use_drift_turnover:\n",
    "            return 0.0\n",
    "\n",
    "        taus = taus_series(eta)\n",
    "        return c_tc * float(np.mean(taus[1:])) if taus.shape[0] > 1 else 0.0 # no drift in the beginning\n",
    "\n",
    "    def objective(eta):\n",
    "        theta = eta_to_theta(eta)\n",
    "        rp = np.sum(theta * R, axis=1)      # monthly portfolio return series, no R_ext!!!\n",
    "        mu_p = float(rp.mean())\n",
    "        var_p = float(rp.var(ddof=0))\n",
    "        return 0.5 * gamma * var_p - mu_p + TC(eta)\n",
    "\n",
    "    # initial guess\n",
    "    guess = np.ones(2 * K) / (2 * K)\n",
    "\n",
    "    constraints = []  # keep empty (no equality constraint): add up to one effect?\n",
    "\n",
    "    # If unconditional benchmark (no timing): force b = 0 AND enforce sum(a)=1 (fully invested)\n",
    "    # Fully invested constraint is needed for valid cost calculation (drift assumes normalized weights)\n",
    "    if bounded_b:\n",
    "        constraints.append({\"type\": \"eq\", \"fun\": lambda eta: np.sum(eta[:K]) - 1.0})  # sum(a) = 1\n",
    "\n",
    "    # bounds: if nonneg True => both a,b >= 0; if False, a >= 0 but b unbounded for volatility timing\n",
    "    if nonneg:\n",
    "        bounds = [(0.0, None)] * (2 * K)  # Both a and b >= 0\n",
    "    else:\n",
    "        bounds = [(0.0, None)] * K + [(None, None)] * K  # a >= 0, b unbounded\n",
    "\n",
    "    # If unconditional benchmark (bounded_b=True): force b = 0\n",
    "    if bounded_b:\n",
    "        bounds = [(0, None)] * K + [(0, 0)] * K  # Force all b values to exactly 0\n",
    "    result = minimize(\n",
    "        objective,\n",
    "        x0=guess,\n",
    "        bounds=bounds,\n",
    "        constraints=constraints,\n",
    "        method='SLSQP',\n",
    "        options={'maxiter': 100000}\n",
    "    )\n",
    "\n",
    "    eta = result.x\n",
    "    a = eta[:K]\n",
    "    b = eta[K:]\n",
    "\n",
    "    theta = eta_to_theta(eta)\n",
    "    weights = pd.DataFrame(theta, index=Rm.index, columns=Rm.columns) # Rm.index cause\n",
    "\n",
    "    # portfolio return in month t: sum_k w_{k,t} * R_{k,t}\n",
    "    port_ret_gross = (weights * Rm).sum(axis=1)\n",
    "\n",
    "    # Substract the costs (month-by-month, consistent with drift turnover)\n",
    "    taus = taus_series(eta) # just\n",
    "    costs = c_tc * taus # monthly\n",
    "    port_ret_net = port_ret_gross - pd.Series(costs, index=Rm.index)\n",
    "\n",
    "    return {\n",
    "        \"a\": pd.Series(a, index=Rm.columns, name=\"a\"),\n",
    "        \"b\": pd.Series(b, index=Rm.columns, name=\"b\"),\n",
    "        \"weights\": weights,\n",
    "        \"portfolio_returns\": port_ret_gross,\n",
    "        \"portfolio_returns_gross\": port_ret_gross,\n",
    "        \"portfolio_returns_net\": port_ret_net,\n",
    "        \"turnover\": pd.Series(taus, index=Rm.index, name=\"turnover\"),\n",
    "        \"costs\": pd.Series(costs, index=Rm.index, name=\"costs\"), # monthly costs\n",
    "        \"opt_result\": result,\n",
    "        \"TC_in_sample\": TC(eta),\n",
    "        \"use_drift_turnover\": use_drift_turnover,\n",
    "        \"bounded_b\": bounded_b\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6b9934e-62be-4a1d-9391-c36585fcc160",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_numpy_determinism(seed=0):\n",
    "    '''\n",
    "    Similarly to RL set up random sets and go over a list of seeds\n",
    "    '''\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def simulate_markov_chain(Q, T, k0=0, rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(0)\n",
    "    Q = np.asarray(Q, float)\n",
    "    K = Q.shape[0]\n",
    "    k = np.empty(T, dtype=int)\n",
    "    k[0] = int(k0)\n",
    "    for t in range(1, T):\n",
    "        k[t] = rng.choice(K, p=Q[k[t - 1]]) # 0,3,1 etc . which regime:)\n",
    "    return k\n",
    "\n",
    "\n",
    "def multivariate_t_eps_with_target_cov(rng, Sigma, df: float):\n",
    "    \"\"\"\n",
    "    eps ~ multivariate t with df, scaled so Cov(eps) = Sigma (for df>2).\n",
    "    Construction: z~N(0,Sigma), scale by s = sqrt(df/chi2_df),\n",
    "    then multiply by sqrt((df-2)/df) to keep covariance = Sigma.\n",
    "    \"\"\"\n",
    "    Sigma = np.asarray(Sigma, float)\n",
    "    z = rng.multivariate_normal(mean=np.zeros(Sigma.shape[0]), cov=Sigma)\n",
    "    g = rng.chisquare(df)\n",
    "    s = np.sqrt(df / g)\n",
    "    eps = z * s * np.sqrt((df - 2.0) / df)  # ensures Cov(eps)=Sigma\n",
    "    return eps\n",
    "\n",
    "\n",
    "def simulate_rs_var1_monthly_regimes_RS_SV_T(\n",
    "    T_days,\n",
    "    Q,\n",
    "    c_list,\n",
    "    Phi,\n",
    "    Sigma_list,\n",
    "    k0=0,\n",
    "    burn_in_months=50,\n",
    "    rng=None,\n",
    "    start_date=\"2000-01-03\",\n",
    "    df_list=None,                 # Student-t df per regime\n",
    "    sv_rho=0.97,                  # persistence of log-vol (vol clustering)\n",
    "    sv_sigma=0.20,                # innovation std of log-vol\n",
    "    logh_mu_list=None,            # regime-specific mean level of log-vol\n",
    "):\n",
    "    \"\"\"\n",
    "    Regime-switching VAR(1) with:\n",
    "      - monthly Markov regimes\n",
    "      - daily VAR(1)\n",
    "      - Student-t shocks (fat tails)\n",
    "      - persistent stochastic volatility scale h_t (vol clustering)\n",
    "    https://en.wikipedia.org/wiki/Multivariate_t-distribution\n",
    "    \n",
    "    Conditional shock covariance: h_t * Sigma_list[regime]\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(0)\n",
    "\n",
    "    Q = np.asarray(Q, float)\n",
    "    c_list = np.asarray(c_list, float)\n",
    "    Sigma_list = np.asarray(Sigma_list, float)\n",
    "\n",
    "    K = Q.shape[0]\n",
    "    N = c_list.shape[1]\n",
    "\n",
    "    Phi_arr = np.asarray(Phi, float)\n",
    "    if Phi_arr.ndim == 2:\n",
    "        Phi_arr = np.repeat(Phi_arr[None, :, :], K, axis=0) # rethink this! we may change this in the example !!!!!!\n",
    "\n",
    "    # defaults\n",
    "    if df_list is None:\n",
    "        df_list = np.full(K, 8.0)  # moderately fat tails everywhere\n",
    "    df_list = np.asarray(df_list, float)\n",
    "\n",
    "    if logh_mu_list is None:\n",
    "        # baseline: low vol in bull, medium in neutral, high in bear #  we may change bull neautr\\l\n",
    "        # interpreted as log(h), where h multiplies Sigma\n",
    "        logh_mu_list = np.array([-2.5, -1.5, -0.5], dtype=float)[:K]\n",
    "    logh_mu_list = np.asarray(logh_mu_list, float)\n",
    "\n",
    "    # Build calendar sample dates\n",
    "    sample_dates = pd.bdate_range(start_date, periods=T_days)\n",
    "    start_month = sample_dates[0].to_period(\"M\")\n",
    "    end_month   = sample_dates[-1].to_period(\"M\")\n",
    "\n",
    "    sample_months = pd.period_range(start=start_month, end=end_month, freq=\"M\")\n",
    "    T_months = len(sample_months)\n",
    "\n",
    "    full_months = pd.period_range(start=(start_month - burn_in_months), end=end_month, freq=\"M\") # we wont use burn in months\n",
    "    TT_months = len(full_months)\n",
    "\n",
    "    # simulate monthly regimes\n",
    "    k_month_full = simulate_markov_chain(Q, TT_months, k0=k0, rng=rng)\n",
    "\n",
    "    # expand to daily regimes aligned to business days\n",
    "    all_dates_full = []\n",
    "    k_days_full = []\n",
    "\n",
    "    for m_idx, per in enumerate(full_months):\n",
    "        month_start = per.to_timestamp(how=\"start\")\n",
    "        month_end   = per.to_timestamp(how=\"end\")\n",
    "        dts = pd.bdate_range(month_start, month_end)\n",
    "\n",
    "        all_dates_full.append(dts)\n",
    "        k_days_full.append(np.full(len(dts), int(k_month_full[m_idx]), dtype=int)) # every business day in a month inherits that monthâ€™s regime\n",
    "\n",
    "    all_dates_full = all_dates_full[0].append(all_dates_full[1:]) if len(all_dates_full) > 1 else all_dates_full[0]\n",
    "    k_days_full = np.concatenate(k_days_full, axis=0)\n",
    "\n",
    "    # simulate daily log returns with SV scale + t innovations\n",
    "    r_full = np.zeros((len(all_dates_full), N), dtype=float)\n",
    "\n",
    "    # initialize log-vol\n",
    "    k0_day = int(k_days_full[0])\n",
    "    logh = float(logh_mu_list[k0_day])  # start at regime mean\n",
    "\n",
    "    for t in range(1, len(all_dates_full)):\n",
    "        kt = int(k_days_full[t])\n",
    "        df = float(df_list[kt])\n",
    "\n",
    "        # stochastic volatility (one-factor scale)\n",
    "        # log h_t = mu_k + rho*(log h_{t-1} - mu_k) + sigma * eta_t\n",
    "        logh = (logh_mu_list[kt] +\n",
    "                sv_rho * (logh - logh_mu_list[kt]) +\n",
    "                sv_sigma * rng.standard_normal())\n",
    "        h = float(np.exp(logh))  # scale multiplier on Sigma\n",
    "\n",
    "        # heavy-tailed shock with target covariance Sigma_list[kt]\n",
    "        eps = multivariate_t_eps_with_target_cov(rng, Sigma_list[kt], df=df)\n",
    "\n",
    "        # apply SV scale (now Cov = h * Sigma_k)\n",
    "        eps = np.sqrt(h) * eps\n",
    "\n",
    "        r_full[t] = c_list[kt] + Phi_arr[kt] @ r_full[t - 1] + eps\n",
    "\n",
    "    # drop burn-in by date indexing\n",
    "    pos = all_dates_full.get_indexer(sample_dates)\n",
    "    r_days = r_full[pos]\n",
    "    k_days = k_days_full[pos]\n",
    "    k_month = k_month_full[-T_months:]\n",
    "    # helper: make sure that dates logic alogn\n",
    "\n",
    "    return r_days, k_days, k_month, sample_dates, sample_months\n",
    "\n",
    "def mv_simple(\n",
    "    daily_ret: pd.DataFrame,\n",
    "    cols=None,\n",
    "    gamma = 5.0,\n",
    "    ridge: float = 1e-10,\n",
    "    sum_to_one_constraint: bool = True,  # True => enforce sum(w)=1; False => no equality constraint\n",
    "    long_only: bool = True,              # True => bounds [0,1]; False => no bounds\n",
    "    maxiter: int = 10000,\n",
    "                        ):\n",
    "    if cols is not None:\n",
    "        daily_ret = daily_ret[cols]\n",
    "    # monthly\n",
    "    Rm_df = compute_monthly_factor_returns_from_daily(daily_ret) # monthly\n",
    "    cols = list(Rm_df.columns)\n",
    "\n",
    "    R = Rm_df.to_numpy()\n",
    "    T, K = R.shape\n",
    "\n",
    "    Sigma = np.cov(R, rowvar=False) + ridge * np.eye(K)\n",
    "    Return = np.mean(R, axis=0)\n",
    "\n",
    "    def objective(w):\n",
    "        w = np.asarray(w, float)\n",
    "        return float(0.5 * gamma * (w @ Sigma @ w) - (w @ Return))\n",
    "\n",
    "    constraints = []\n",
    "    if sum_to_one_constraint:\n",
    "        constraints.append({\"type\": \"eq\", \"fun\": lambda w: np.sum(w) - 1.0})\n",
    "\n",
    "    if long_only:\n",
    "        bounds = [(0.0, 1)] * K\n",
    "    else:\n",
    "        bounds = None  # not bounding is false => no bounds at all\n",
    "\n",
    "    x0 = np.ones(K) / K  # simple start\n",
    "\n",
    "    res = minimize(\n",
    "        objective,\n",
    "        x0=x0,\n",
    "        method=\"SLSQP\",\n",
    "        bounds=bounds,\n",
    "        constraints=constraints,\n",
    "        options={\"maxiter\": maxiter},\n",
    "    )\n",
    "\n",
    "    w = np.asarray(res.x, float)\n",
    "    w = pd.Series(w, index=cols, name=\"w_mv\")\n",
    "\n",
    "    # monthly portfolio return series (gross, no cost)\n",
    "    port_monthly = pd.Series(Rm_df.to_numpy() @ w.to_numpy(), index=Rm_df.index, name=\"port_mv\")\n",
    "\n",
    "    return {\n",
    "        \"weights\": w,\n",
    "        \"monthly_returns\": Rm_df,\n",
    "        \"port_monthly\": port_monthly,\n",
    "        \"Sigma\": Sigma,\n",
    "        \"opt_result\": res,\n",
    "        \"sum_to_one_constraint\": sum_to_one_constraint,\n",
    "        \"long_only\": long_only,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def mw_cvar_simple(\n",
    "    daily_ret: pd.DataFrame,\n",
    "    cols=None,\n",
    "    beta: float = 0.95,                 # CVaR confidence level\n",
    "    gamma: float = 1.0,                 # tradeoff weight on CVaR: 1!\n",
    "    sum_to_one_constraint: bool = True, # enforce sum(w)=1\n",
    "    long_only: bool = True,             # enforce w>=0\n",
    "    upper_bound: float | None = 1.0,    # set None to remove w<=upper_bound\n",
    "    solver: str = \"ECOS\",\n",
    "    verbose: bool = False,\n",
    "        ):\n",
    "    if cols is not None:\n",
    "        daily_ret = daily_ret[cols]\n",
    "\n",
    "    # monthly returns\n",
    "    Rm_df = compute_monthly_factor_returns_from_daily(daily_ret)\n",
    "    asset_cols = list(Rm_df.columns)\n",
    "\n",
    "    R = Rm_df.to_numpy()  # (T, K)\n",
    "    T, K = R.shape\n",
    "    print(f\"R shape: T (months) = {T:,},  K (assets) = {K:,}\")\n",
    "\n",
    "    mu_vec = R.mean(axis=0)  # (K,)\n",
    "\n",
    "    # CVXPY variables\n",
    "    w = cp.Variable(K)\n",
    "    alpha = cp.Variable()      # VaR-like threshold\n",
    "    u = cp.Variable(T)         # tail slacks\n",
    "\n",
    "    # losses = - portfolio return\n",
    "    losses = -(R @ w)          # (T,)\n",
    "\n",
    "    # CVaR(loss) definition\n",
    "    cvar = alpha + (1 / ((1 - beta) * T)) * cp.sum(u)\n",
    "\n",
    "    constraints = [\n",
    "        u >= 0,\n",
    "        u >= losses - alpha\n",
    "    ]\n",
    "\n",
    "    if sum_to_one_constraint:\n",
    "        constraints.append(cp.sum(w) == 1)\n",
    "\n",
    "    if long_only:\n",
    "        constraints.append(w >= 0)\n",
    "\n",
    "    if upper_bound is not None:\n",
    "        constraints.append(w <= upper_bound)\n",
    "\n",
    "    # minimize: gamma * CVaR(loss) - expected_return\n",
    "    objective = cp.Minimize(gamma * cvar - mu_vec @ w)\n",
    "\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve(solver=solver, verbose=verbose)\n",
    "\n",
    "    if prob.status not in (\"optimal\", \"optimal_inaccurate\"):\n",
    "        raise RuntimeError(f\"CVaR optimization failed. Status: {prob.status}\")\n",
    "\n",
    "    w_val = np.asarray(w.value, float).reshape(-1)\n",
    "    w_ser = pd.Series(w_val, index=asset_cols, name=\"w_mw_cvar\")\n",
    "\n",
    "    # monthly portfolio return series\n",
    "    port_monthly = pd.Series(Rm_df.to_numpy() @ w_ser.to_numpy(),\n",
    "                             index=Rm_df.index,\n",
    "                             name=\"port_mw_cvar\")\n",
    "\n",
    "    out = {\n",
    "        \"weights\": w_ser,\n",
    "        \"monthly_returns\": Rm_df,\n",
    "        \"port_monthly\": port_monthly,\n",
    "        \"mu_vec\": pd.Series(mu_vec, index=asset_cols, name=\"mu\"),\n",
    "        \"beta\": beta,\n",
    "        \"gamma\": gamma,\n",
    "        \"cvar_loss\": float(cvar.value),\n",
    "        \"var_alpha\": float(alpha.value),\n",
    "        \"expected_return\": float(mu_vec @ w_val),\n",
    "        \"opt_status\": prob.status,\n",
    "        \"opt_value\": float(prob.value),\n",
    "        \"problem\": prob,   # keep if you want to inspect duals etc.\n",
    "        \"sum_to_one_constraint\": sum_to_one_constraint,\n",
    "        \"long_only\": long_only,\n",
    "        \"upper_bound\": upper_bound,\n",
    "    }\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14a94b65-c689-46b1-845d-bc2565dc8b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = [89, 53, 274, 1234]  \n",
    "regime_names = [\"Bull\", \"Neutral\", \"Bear\"]\n",
    "df_list = np.array([20.0, 10.0, 5.0])\n",
    "logh_mu_list = np.array([-1.6, -1.3, -0.7])\n",
    "sv_rho, sv_sigma = 0.97, 0.20\n",
    "\n",
    "\n",
    "# transition matrix matter more i think if we have enough data.\n",
    "Phi_fixed = np.array([[0.15, 0.10],\n",
    "                      [0.10, 0.15]])\n",
    "\n",
    "c_list = np.array([\n",
    "    [0.0040, 0.0030],   # Bull\n",
    "    [0.0030, 0.0028],   # Neutral\n",
    "    [-0.0090, 0.0030],  # Bear\n",
    "])\n",
    "\n",
    "Sigma_list = np.array([\n",
    "    [[0.0005, 0.00010],\n",
    "     [0.00010, 0.00045]],   # Bull\n",
    "    [[0.0018, 0.0],\n",
    "     [0.0,    0.0014]],     # Neutral\n",
    "    [[0.0050, -0.0030],\n",
    "     [-0.0030, 0.0020]],    # Bear\n",
    "])\n",
    "\n",
    "Q_bull_bear = np.array([\n",
    "    [0.74, 0.02, 0.24],\n",
    "    [0.10, 0.82, 0.08],\n",
    "    [0.30, 0.02, 0.68],\n",
    "])\n",
    "\n",
    "Q_neutral_bear = np.array([\n",
    "    [0.82, 0.08, 0.10],\n",
    "    [0.02, 0.68, 0.30],\n",
    "    [0.02, 0.24, 0.74],\n",
    "])\n",
    "\n",
    "Q_bull_neutral = np.array([\n",
    "    [0.74, 0.24, 0.02],\n",
    "    [0.30, 0.68, 0.02],\n",
    "    [0.10, 0.08, 0.82],\n",
    "])\n",
    "scenarios = [\n",
    "    (\"Bull-Bear\", Q_bull_bear),\n",
    "    (\"Neutral-Bear\", Q_neutral_bear),\n",
    "    (\"Bull-Neutral\", Q_bull_neutral),\n",
    "]\n",
    "\n",
    "results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36b82bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi stable: max |eig| = 0.250000\n"
     ]
    }
   ],
   "source": [
    "def check_phi_stability(Phi, tol=1.0 - 1e-8):\n",
    "    Phi = np.asarray(Phi, float)\n",
    "    if Phi.ndim == 2:\n",
    "        eigs = np.linalg.eigvals(Phi)\n",
    "        max_abs = float(np.max(np.abs(eigs)))\n",
    "        if max_abs >= tol:\n",
    "            raise RuntimeError(f\"Unstable VAR: max |eig| = {max_abs:.6f} >= 1.0\")\n",
    "        print(f\"Phi stable: max |eig| = {max_abs:.6f}\")\n",
    "        return\n",
    "    if Phi.ndim == 3:\n",
    "        for k in range(Phi.shape[0]):\n",
    "            eigs = np.linalg.eigvals(Phi[k])\n",
    "            max_abs = float(np.max(np.abs(eigs)))\n",
    "            if max_abs >= tol:\n",
    "                raise RuntimeError(f\"Unstable VAR in regime {k}: max |eig| = {max_abs:.6f} >= 1.0\")\n",
    "        print(\"Phi stable in all regimes.\")\n",
    "        return\n",
    "    raise ValueError(\"Phi must be 2D or 3D\")\n",
    "\n",
    "# Check current Phi_fixed\n",
    "check_phi_stability(Phi_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cad0900c-c6f9-4e5a-9ad9-06db2073d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81133b97-9a6f-4f84-b184-800b1770337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening original files\n",
    "tau_levels = [0.1,0.5,0.9] \n",
    "tau_levels_str = [str(tau).replace('.', '') for tau in tau_levels]\n",
    "seeds = [53,274,1234,89] # seem seeds before\n",
    "\n",
    "#base_path =\"C:/Users/95att/Desktop/job/First_paper_QAC/Model based RL Gauss/training_outcome/\"\n",
    "base_path = \"C:/Users/95att/Desktop/job/First_paper_QAC/Model based RL Dirichlet/training_outcome/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1fc746e-d398-4303-b881-4d7297b2dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_seed_outputs(\n",
    "    base_path,\n",
    "    tau_levels=(0.1, 0.5, 0.9),\n",
    "    seed_list=(53,274,1234,89),\n",
    "    folder_template=\"20250911_final_weighted_q_spwise_standard_tanh_{seed}_{tau_str}\",\n",
    "    filename=\"snapshot_train_end_summary_full.pkl\",\n",
    "                        ):\n",
    "\n",
    "    base_path = Path(base_path) # Creating a path object\n",
    "    tau_levels_str = [str(t).replace(\".\", \"\") for t in tau_levels]\n",
    "\n",
    "    out, paths = {}, {}\n",
    "    for tau_str in tau_levels_str:\n",
    "        out[tau_str] = {}\n",
    "        paths[tau_str] = {}\n",
    "        for seed in seed_list:\n",
    "            folder_name = folder_template.format(seed=seed, tau_str=tau_str)\n",
    "            fpath = base_path / folder_name / filename\n",
    "            if not fpath.exists():\n",
    "                print(f\"File not found: {fpath}\")\n",
    "                continue\n",
    "            with open(fpath, \"rb\") as fh:\n",
    "                payload = pickle.load(fh)\n",
    "            out[tau_str][seed] = payload\n",
    "            paths[tau_str][seed] = str(fpath)\n",
    "    return out, paths#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "823d2bda-523a-4050-b23a-f6729e2444b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_bull_bear, found_paths_bull_bear = load_seed_outputs(\n",
    "    base_path=base_path,\n",
    "    tau_levels=tau_levels,\n",
    "    seed_list=seeds,\n",
    "    folder_template=\"final_Q_bull_bear_original_{seed}_{tau_str}\",\n",
    "    filename=\"snapshot_train_end_summary_full.pkl\",\n",
    ")\n",
    "nested_bull_neutral, found_paths_bull_bear = load_seed_outputs(\n",
    "    base_path=base_path,\n",
    "    tau_levels=tau_levels,\n",
    "    seed_list=seeds,\n",
    "    folder_template=\"final_Q_bull_neutral_original_{seed}_{tau_str}\",\n",
    "    filename=\"snapshot_train_end_summary_full.pkl\",\n",
    ")\n",
    "\n",
    "nested_neutral_bear, found_paths_bull_bear = load_seed_outputs(\n",
    "    base_path=base_path,\n",
    "    tau_levels=tau_levels,\n",
    "    seed_list=seeds,\n",
    "    folder_template=\"final_Q_neutral_bear_original_{seed}_{tau_str}\",\n",
    "    filename=\"snapshot_train_end_summary_full.pkl\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cad347f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff0d1f4",
   "metadata": {},
   "source": [
    "# In-Sample Simulation Framework (No Saving)\n",
    "\n",
    "This section simulates Markov regime-switching returns and evaluates strategies.\n",
    "Outputs are displayed only (no files are saved)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5773fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MarkovSimulationEnvironment:\n",
    "    # TODO: loop over seed and test seeds, align with RL\n",
    "    def __init__(self, Q, c_list, Phi, Sigma_list, regime_names,\n",
    "                 T_days=252*50, seed=123, burn_in_months=50,\n",
    "                 start_date=\"2000-01-03\", k0=0, asset_names=None,\n",
    "                 df_list=None, sv_rho=0.97, sv_sigma=0.20, logh_mu_list=None,\n",
    "                 verbose: bool = False):\n",
    "        \"\"\"\n",
    "        Q: Transition matrix (K x K)\n",
    "        c_list: Drift per regime (K x N)\n",
    "        Phi: AR(1) coefficient matrix (N x N) or (K x N x N)\n",
    "        Sigma_list: Covariance per regime (K x N x N)\n",
    "        regime_names: List of regime names\n",
    "        df_list: Student-t df per regime (length K)\n",
    "        sv_rho: persistence of log-vol (vol clustering)\n",
    "        sv_sigma: innovation std of log-vol\n",
    "        logh_mu_list: regime-specific mean level of log-vol (length K)\n",
    "        \"\"\"\n",
    "        self.Q = np.asarray(Q, float)\n",
    "        self.c_list = np.asarray(c_list, float)\n",
    "        self.Phi = np.asarray(Phi, float)\n",
    "        self.Sigma_list = np.asarray(Sigma_list, float)\n",
    "        self.regime_names = regime_names\n",
    "        self.T_days = T_days\n",
    "        self.seed = seed\n",
    "        self.burn_in_months = burn_in_months\n",
    "        self.start_date = start_date\n",
    "        self.k0 = k0\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.K = len(regime_names)\n",
    "        self.N = self.c_list.shape[1]\n",
    "        self.asset_names = asset_names or [f\"Asset{i+1}\" for i in range(self.N)]\n",
    "        \n",
    "        self.df_list = df_list\n",
    "        self.sv_rho = sv_rho\n",
    "        self.sv_sigma = sv_sigma\n",
    "        self.logh_mu_list = logh_mu_list\n",
    "        \n",
    "        self.daily_returns_df = None\n",
    "        self.monthly_returns_df = None\n",
    "        self.daily_regimes = None\n",
    "        self.monthly_regimes = None\n",
    "        self.dates = None\n",
    "        self.sample_months = None\n",
    "        \n",
    "    def _expand_regime_param(self, values, fill_value):\n",
    "        values = np.asarray(values, float) if values is not None else None\n",
    "        if values is None:\n",
    "            return np.full(self.K, fill_value, dtype=float)\n",
    "        if values.size < self.K:\n",
    "            return np.pad(values, (0, self.K - values.size), constant_values=fill_value)\n",
    "        return values[:self.K]\n",
    "        \n",
    "    def simulate(self):\n",
    "        set_numpy_determinism(self.seed)\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "    \n",
    "        df_list = self._expand_regime_param(self.df_list, 8.0)\n",
    "        logh_mu_list = self._expand_regime_param(self.logh_mu_list, -1.0)\n",
    "        sv_rho = float(self.sv_rho)\n",
    "        sv_sigma = float(self.sv_sigma)\n",
    "    \n",
    "        r_log, k_daily, k_month, dates, sample_months = simulate_rs_var1_monthly_regimes_RS_SV_T(\n",
    "            T_days=self.T_days,\n",
    "            Q=self.Q,\n",
    "            c_list=self.c_list,\n",
    "            Phi=self.Phi,\n",
    "            Sigma_list=self.Sigma_list,\n",
    "            k0=self.k0,\n",
    "            burn_in_months=self.burn_in_months,\n",
    "            rng=rng,\n",
    "            start_date=self.start_date,\n",
    "            df_list=df_list,\n",
    "            sv_rho=sv_rho,\n",
    "            sv_sigma=sv_sigma,\n",
    "            logh_mu_list=logh_mu_list,\n",
    "        )\n",
    "    \n",
    "        # Convert log returns to simple returns\n",
    "        r_simple = np.exp(r_log) - 1.0\n",
    "    \n",
    "        # Store daily returns\n",
    "        self.daily_returns_df = pd.DataFrame(\n",
    "            r_simple,\n",
    "            index=dates,\n",
    "            columns=self.asset_names\n",
    "        )\n",
    "    \n",
    "        # Store daily regimes (named)\n",
    "        self.daily_regimes = (\n",
    "            pd.Series(k_daily, index=dates, name=\"regime_int\")\n",
    "            .map(lambda x: self.regime_names[int(x)])\n",
    "        )\n",
    "        self.daily_regimes.name = \"regime\"\n",
    "    \n",
    "        # Compute monthly returns FIRST (defines the \"month-end\" index as last trading day)\n",
    "        self.monthly_returns_df = compute_monthly_factor_returns_from_daily(\n",
    "            self.daily_returns_df,\n",
    "            factor_cols=self.asset_names\n",
    "        )\n",
    "    \n",
    "        # Build monthly regimes indexed EXACTLY like monthly_returns_df.index\n",
    "        # k_month is aligned to sample_months (PeriodIndex, monthly)\n",
    "        k_month_ser = pd.Series(k_month, index=sample_months, name=\"regime_int\")\n",
    "    \n",
    "        idx = self.monthly_returns_df.index  # last trading day timestamps\n",
    "        self.monthly_regimes = (\n",
    "            k_month_ser\n",
    "            .reindex(idx.to_period(\"M\"))          # month period -> regime int\n",
    "            .set_axis(idx)                        # index = last trading day timestamps\n",
    "            .map(lambda x: self.regime_names[int(x)])  # int -> regime name\n",
    "        )\n",
    "        self.monthly_regimes.name = \"regime\"\n",
    "    \n",
    "        self.dates = dates\n",
    "        self.sample_months = sample_months\n",
    "    \n",
    "        # Optional sanity check: should match perfectly\n",
    "        if self.verbose:\n",
    "            ok = self.monthly_regimes.index.equals(self.monthly_returns_df.index)\n",
    "            print(f\"  Simulated {len(self.daily_returns_df):,} days across {len(self.monthly_returns_df)} months\")\n",
    "            print(f\"  Monthly regime index aligned to monthly returns: {ok}\")\n",
    "            print(f\"  Daily regime distribution: {self.daily_regimes.value_counts().to_dict()}\")\n",
    "    \n",
    "        return self\n",
    "    \n",
    "\n",
    "    \n",
    "    def save_simulation_data(self, filepath):\n",
    "        \"\"\"Save all simulation data to pickle\"\"\"\n",
    "        data = {\n",
    "            'daily_returns': self.daily_returns_df,\n",
    "            'monthly_returns': self.monthly_returns_df,\n",
    "            'daily_regimes': self.daily_regimes,\n",
    "            'monthly_regimes': self.monthly_regimes,\n",
    "            'dates': self.dates,\n",
    "            'sample_months': self.sample_months,\n",
    "            'parameters': {\n",
    "                'Q': self.Q,\n",
    "                'c_list': self.c_list,\n",
    "                'Phi': self.Phi,\n",
    "                'Sigma_list': self.Sigma_list,\n",
    "                'regime_names': self.regime_names,\n",
    "                'seed': self.seed,\n",
    "                'asset_names': self.asset_names,\n",
    "                'df_list': self.df_list,\n",
    "                'sv_rho': self.sv_rho,\n",
    "                'sv_sigma': self.sv_sigma,\n",
    "                'logh_mu_list': self.logh_mu_list\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "        if self.verbose:\n",
    "            print(f\" Saved simulation data to {filepath}\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def load_simulation_data(filepath):\n",
    "        with open(filepath, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        print(f\" Loaded simulation data from {filepath}\")\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37368f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyBacktester:\n",
    "\n",
    "    \n",
    "    def __init__(self, env, verbose: bool = False):\n",
    "        self.env = env\n",
    "        self.results = {}\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def _log(self, msg: str):\n",
    "        if self.verbose:\n",
    "            print(msg)\n",
    "        \n",
    "    def run_volatility_management(self, name=\"VolManagement\", ridge=1e-8, gamma=5.0, c_tc=0.0021):\n",
    "        self._log(f\"\\n[{name}] Running...\")\n",
    "        \n",
    "        result = Markowitz_with_turnover_TC_diffobj(\n",
    "            daily_factors=self.env.daily_returns_df,\n",
    "            factor_cols=self.env.asset_names,\n",
    "            gamma=gamma,\n",
    "            ridge=ridge,\n",
    "            nonneg=True,\n",
    "            c_tc=c_tc,\n",
    "            use_drift_turnover=True,\n",
    "            bounded_b=False  # Allow volatility timing via b parameters\n",
    "        )\n",
    "        \n",
    "        # Compute daily returns from monthly weights\n",
    "        # check this. do we scale with Mkt-rf?\n",
    "        daily_port_returns = daily_portfolio_returns_from_monthly_weights(\n",
    "            self.env.daily_returns_df,\n",
    "            result['weights']\n",
    "        )\n",
    "        \n",
    "        # Get weights by regime\n",
    "        weights_by_regime = self._compute_weights_by_regime_markowitz(\n",
    "            result['weights']\n",
    "        )\n",
    "        \n",
    "        self.results[name] = {\n",
    "            'daily_returns': daily_port_returns,\n",
    "            'monthly_returns': result['portfolio_returns_net'],\n",
    "            'weights_monthly': result['weights'],\n",
    "            'turnover': result['turnover'],\n",
    "            'costs': result['costs'],\n",
    "            'a_params': result['a'],\n",
    "            'b_params': result['b'],\n",
    "            'weights_by_regime': weights_by_regime,\n",
    "            'type': 'VolManagement'\n",
    "        }\n",
    "        \n",
    "        self._log(f\"   Vol-timing params (b): {result['b'].round(4).to_dict()}\")\n",
    "        return self\n",
    "    \n",
    "    def run_markowitz(self, name=\"Markowitz\", gamma=5.0, c_tc=0.0021, \n",
    "                      use_drift_turnover=True, bounded_b=False, ridge=1e-8):\n",
    "        self._log(f\"\\n[{name}] Running...\")\n",
    "        \n",
    "        result = Markowitz_with_turnover_TC_diffobj(\n",
    "            daily_factors=self.env.daily_returns_df,\n",
    "            factor_cols=self.env.asset_names,\n",
    "            gamma=gamma,\n",
    "            ridge=ridge,\n",
    "            nonneg=True,\n",
    "            c_tc=c_tc,\n",
    "            use_drift_turnover=use_drift_turnover,\n",
    "            bounded_b=bounded_b\n",
    "        )\n",
    "        \n",
    "        daily_port_returns = daily_portfolio_returns_from_monthly_weights(\n",
    "            self.env.daily_returns_df,\n",
    "            result['weights']\n",
    "        )\n",
    "        \n",
    "        weights_by_regime = self._compute_weights_by_regime_markowitz(\n",
    "            result['weights']\n",
    "        )\n",
    "        \n",
    "        self.results[name] = {\n",
    "            'daily_returns': daily_port_returns,\n",
    "            'monthly_returns': result['portfolio_returns_net'],\n",
    "            'weights_monthly': result['weights'],\n",
    "            'turnover': result['turnover'],\n",
    "            'costs': result['costs'],\n",
    "            'a_params': result['a'],\n",
    "            'b_params': result['b'],\n",
    "            'weights_by_regime': weights_by_regime,\n",
    "            'type': 'Markowitz'\n",
    "        }\n",
    "        \n",
    "        self._log(f\"  Avg monthly turnover: {result['turnover'].mean():.4f}\")\n",
    "        return self\n",
    "    \n",
    "    def run_equal_weight(self, name=\"EqualWeight\"):\n",
    "        self._log(f\"\\n[{name}] Running...\")\n",
    "        \n",
    "        weights = pd.Series(\n",
    "            1.0 / self.env.N, \n",
    "            index=self.env.asset_names\n",
    "        )\n",
    "        \n",
    "        daily_port_returns = (self.env.daily_returns_df @ weights)\n",
    "        monthly_port_returns = (1 + daily_port_returns).groupby(\n",
    "            daily_port_returns.index.to_period(\"M\")\n",
    "        ).prod() - 1.0\n",
    "        monthly_port_returns.index = monthly_port_returns.index.to_timestamp(\"M\")\n",
    "        \n",
    "        weights_by_regime = pd.DataFrame(\n",
    "            {regime: weights for regime in self.env.regime_names}\n",
    "        ).T\n",
    "        \n",
    "        self.results[name] = {\n",
    "            'daily_returns': daily_port_returns,\n",
    "            'monthly_returns': monthly_port_returns,\n",
    "            'weights': weights,\n",
    "            'weights_by_regime': weights_by_regime,\n",
    "            'type': 'EqualWeight'\n",
    "        }\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def run_mv_simple(self, name=\"MV_Simple\", gamma=5.0, ridge=1e-10, \n",
    "                      sum_to_one_constraint=True, long_only=True):\n",
    "        self._log(f\"\\n[{name}] Running...\")\n",
    "        \n",
    "        result = mv_simple(\n",
    "            daily_ret=self.env.daily_returns_df,\n",
    "            cols=self.env.asset_names,\n",
    "            gamma=gamma,\n",
    "            ridge=ridge,\n",
    "            sum_to_one_constraint=sum_to_one_constraint,\n",
    "            long_only=long_only\n",
    "        )\n",
    "        \n",
    "        weights_series = result['weights']\n",
    "        daily_port_returns = (self.env.daily_returns_df @ weights_series)\n",
    "        \n",
    "        weights_by_regime = pd.DataFrame(\n",
    "            {regime: weights_series for regime in self.env.regime_names}\n",
    "        ).T\n",
    "        \n",
    "        self.results[name] = {\n",
    "            'daily_returns': daily_port_returns,\n",
    "            'monthly_returns': result['port_monthly'],\n",
    "            'weights': weights_series,\n",
    "            'weights_by_regime': weights_by_regime,\n",
    "            'type': 'MV_Simple'\n",
    "        }\n",
    "        \n",
    "        self._log(f\"   Weights: {weights_series.round(4).to_dict()}\")\n",
    "        return self\n",
    "    \n",
    "    def run_mw_cvar_simple(self, name=\"MV_CVaR\", beta=0.95, gamma=1.0,\n",
    "                           sum_to_one_constraint=True, long_only=True, \n",
    "                           upper_bound=1.0, solver=\"ECOS\"):\n",
    "        \"\"\"Run mean-variance CVaR optimization (unconditional, no vol timing, no turnover costs)\"\"\"\n",
    "        self._log(f\"\\n[{name}] Running...\")\n",
    "        \n",
    "        try:\n",
    "            import cvxpy as cp\n",
    "        except ImportError:\n",
    "            self._log(\"  âœ— CVXPY not installed. Skipping MV-CVaR strategy.\")\n",
    "            return self\n",
    "        \n",
    "        result = mw_cvar_simple(\n",
    "            daily_ret=self.env.daily_returns_df,\n",
    "            cols=self.env.asset_names,\n",
    "            beta=beta,\n",
    "            gamma=gamma,\n",
    "            sum_to_one_constraint=sum_to_one_constraint,\n",
    "            long_only=long_only,\n",
    "            upper_bound=upper_bound,\n",
    "            solver=solver,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        weights_series = result['weights']\n",
    "        daily_port_returns = (self.env.daily_returns_df @ weights_series)\n",
    "        \n",
    "        weights_by_regime = pd.DataFrame(\n",
    "            {regime: weights_series for regime in self.env.regime_names}\n",
    "        ).T\n",
    "        \n",
    "        self.results[name] = {\n",
    "            'daily_returns': daily_port_returns,\n",
    "            'monthly_returns': result['port_monthly'],\n",
    "            'weights': weights_series,\n",
    "            'weights_by_regime': weights_by_regime,\n",
    "            'cvar_loss': result['cvar_loss'],\n",
    "            'type': 'MV_CVaR'\n",
    "        }\n",
    "        \n",
    "        self._log(f\"   Weights: {weights_series.round(4).to_dict()}\")\n",
    "        self._log(f\"   CVaR (loss): {result['cvar_loss']:.6f}\")\n",
    "        return self\n",
    "    \n",
    "    def _compute_weights_by_regime_markowitz(self, weights_monthly):\n",
    "        common = weights_monthly.index.intersection(self.env.monthly_regimes.index)\n",
    "        \n",
    "        regime_weights = []\n",
    "        for regime in self.env.regime_names:\n",
    "            mask = self.env.monthly_regimes.loc[common] == regime\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            avg_weights = weights_monthly.loc[common][mask].mean()\n",
    "            \n",
    "            weights = avg_weights.to_dict()\n",
    "            weights['Regime'] = regime\n",
    "            regime_weights.append(weights)\n",
    "        \n",
    "        return pd.DataFrame(regime_weights).set_index('Regime')\n",
    "    \n",
    "    def save_results(self, filepath):\n",
    "        data = {\n",
    "            'results': self.results,\n",
    "            'environment': {\n",
    "                'regime_names': self.env.regime_names,\n",
    "                'asset_names': self.env.asset_names,\n",
    "                'seed': self.env.seed\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "        if self.verbose:\n",
    "            print(f\"Saved backtest results to {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bca71a",
   "metadata": {},
   "source": [
    "## Run All Scenarios and Generate Comprehensive Tables\n",
    "\n",
    "This section runs all three regime-switching scenarios and generates performance tables for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "459d8308",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MarkovSimulationEnvironment.__init__() got an unexpected keyword argument 'df_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m all_performance_tables \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scenario_name, Q_matrix \u001b[38;5;129;01min\u001b[39;00m scenarios_config:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# 1. Create and run simulation\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     env \u001b[38;5;241m=\u001b[39m MarkovSimulationEnvironment(\n\u001b[0;32m     18\u001b[0m         Q\u001b[38;5;241m=\u001b[39mQ_matrix,\n\u001b[0;32m     19\u001b[0m         c_list\u001b[38;5;241m=\u001b[39mc_list,\n\u001b[0;32m     20\u001b[0m         Phi\u001b[38;5;241m=\u001b[39mPhi_fixed,\n\u001b[0;32m     21\u001b[0m         Sigma_list\u001b[38;5;241m=\u001b[39mSigma_list,\n\u001b[0;32m     22\u001b[0m         regime_names\u001b[38;5;241m=\u001b[39mregime_names,\n\u001b[0;32m     23\u001b[0m         T_days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m252\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m,  \u001b[38;5;66;03m# 70 years total: 50 years training + 20 years testing\u001b[39;00m\n\u001b[0;32m     24\u001b[0m         seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m,\n\u001b[0;32m     25\u001b[0m         burn_in_months\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     26\u001b[0m         start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2000-01-03\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m         k0\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     28\u001b[0m         asset_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsset1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsset2\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     29\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     30\u001b[0m         df_list\u001b[38;5;241m=\u001b[39mdf_list,\n\u001b[0;32m     31\u001b[0m         sv_rho\u001b[38;5;241m=\u001b[39msv_rho,\n\u001b[0;32m     32\u001b[0m         sv_sigma\u001b[38;5;241m=\u001b[39msv_sigma,\n\u001b[0;32m     33\u001b[0m         logh_mu_list\u001b[38;5;241m=\u001b[39mlogh_mu_list\n\u001b[0;32m     34\u001b[0m     )\n\u001b[0;32m     36\u001b[0m     env\u001b[38;5;241m.\u001b[39msimulate()\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# 2. Run backtest with all strategies\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: MarkovSimulationEnvironment.__init__() got an unexpected keyword argument 'df_list'"
     ]
    }
   ],
   "source": [
    "df_list = np.array([20.0, 10.0, 5.0])\n",
    "logh_mu_list = np.array([-1.6, -1.3, -0.7])\n",
    "sv_rho, sv_sigma = 0.97, 0.20\n",
    "\n",
    "scenarios_config = [\n",
    "    (\"Bull_Bear\", Q_bull_bear),\n",
    "    (\"Neutral_Bear\", Q_neutral_bear),\n",
    "    (\"Bull_Neutral\", Q_bull_neutral),\n",
    "]\n",
    "\n",
    "# Storage for all results\n",
    "all_scenario_results = {}\n",
    "all_performance_tables = {}\n",
    "# TODO add the df list, sv rho sv sigm and logh mu list to the environment\n",
    "for scenario_name, Q_matrix in scenarios_config:\n",
    "    env = MarkovSimulationEnvironment(\n",
    "        Q=Q_matrix,\n",
    "        c_list=c_list,\n",
    "        Phi=Phi_fixed,\n",
    "        Sigma_list=Sigma_list,\n",
    "        regime_names=regime_names,\n",
    "        T_days=252*50,  # 70 years total: 50 years training + 20 years testing\n",
    "        seed=123,\n",
    "        burn_in_months=50,\n",
    "        start_date=\"2000-01-03\",\n",
    "        k0=0,\n",
    "        asset_names=[\"Asset1\", \"Asset2\"],\n",
    "        verbose=False,\n",
    "        df_list=df_list,\n",
    "        sv_rho=sv_rho,\n",
    "        sv_sigma=sv_sigma,\n",
    "        logh_mu_list=logh_mu_list\n",
    "    )\n",
    "\n",
    "    env.simulate()\n",
    "\n",
    "    # Run backtest with all strategies\n",
    "    backtester = StrategyBacktester(env, verbose=False)\n",
    "    backtester.run_equal_weight(\"EqualWeight\")\n",
    "    backtester.run_mv_simple(\"MV_Simple\", gamma=5.0)\n",
    "    backtester.run_mw_cvar_simple(\"MV_CVaR\", beta=0.95, gamma=5.0)\n",
    "    backtester.run_volatility_management(\"VolManagement\", gamma=5.0, c_tc=0.0021)\n",
    "    backtester.run_markowitz(\"VolManagement_Unconditional\", gamma=5.0, c_tc=0.0021,\n",
    "                             use_drift_turnover=True, bounded_b=True)\n",
    "\n",
    "    # 3. Monthly-return performance table\n",
    "    portfolios = {name: data['monthly_returns'] for name, data in backtester.results.items()}\n",
    "    perf_table = make_table_for_portfolios(portfolios, periods_per_year=12)\n",
    "\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(f\"MONTHLY-RETURN PERFORMANCE TABLE: {scenario_name.replace('_', '-')}\")\n",
    "    print(\"-\"*60)\n",
    "    print(perf_table.round(3).to_string())\n",
    "\n",
    "    # 4. Minimal summary (Sharpe + Tail-Adj Sharpe)\n",
    "    summary = pd.DataFrame({\n",
    "        \"Sharpe (ann.)\": perf_table.loc[\"Sharpe (ann.)\"],\n",
    "        \"Tail-Adj Sharpe (CVaR95)\": perf_table.loc[\"Tail-Adj Sharpe (CVaR95)\"]\n",
    "    })\n",
    "    print(\"\\nSummary (risk-adjusted vs tail-adjusted):\")\n",
    "    print(summary.round(3).to_string())\n",
    "\n",
    "    # Store for comparison\n",
    "    all_scenario_results[scenario_name] = {\n",
    "        'env': env,\n",
    "        'backtester': backtester,\n",
    "        'perf_table': perf_table\n",
    "    }\n",
    "    all_performance_tables[scenario_name] = perf_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1078d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# COMPARATIVE ANALYSIS ACROSS SCENARIOS\n",
    "# ====================================================================\n",
    "\n",
    "# Compare Sharpe ratios across scenarios\n",
    "sharpe_comparison = pd.DataFrame()\n",
    "for scenario_name, results in all_performance_tables.items():\n",
    "    sharpe_comparison[scenario_name] = results.loc['Sharpe (ann.)']\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"SHARPE RATIO COMPARISON\")\n",
    "print(\"-\"*60)\n",
    "print(sharpe_comparison.round(3).to_string())\n",
    "\n",
    "# Compare annualized returns across scenarios\n",
    "return_comparison = pd.DataFrame()\n",
    "for scenario_name, results in all_performance_tables.items():\n",
    "    return_comparison[scenario_name] = results.loc['Ann. Mean (%)']\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"ANNUALIZED RETURN COMPARISON (%)\")\n",
    "print(\"-\"*60)\n",
    "print(return_comparison.round(2).to_string())\n",
    "\n",
    "# Compare CVaR across scenarios\n",
    "cvar_comparison = pd.DataFrame()\n",
    "for scenario_name, results in all_performance_tables.items():\n",
    "    cvar_comparison[scenario_name] = results.loc['CVaR 95% (%)']\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"CVaR 95% COMPARISON (%) - Lower is more negative tail risk\")\n",
    "print(\"-\"*60)\n",
    "print(cvar_comparison.round(3).to_string())\n",
    "\n",
    "# Compare Avg Drawdown across scenarios\n",
    "dd_comparison = pd.DataFrame()\n",
    "for scenario_name, results in all_performance_tables.items():\n",
    "    dd_comparison[scenario_name] = results.loc['Avg DD (%)']\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"AVERAGE DRAWDOWN COMPARISON (%)\")\n",
    "print(\"-\"*60)\n",
    "print(dd_comparison.round(2).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050916ce-78be-43f3-b557-9ebe6f03f990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e03b66e9",
   "metadata": {},
   "source": [
    "## Interpretation of Results Across Scenarios\n",
    "\n",
    "Based on the VAR(1) regime-switching model, here's what we expect to see:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec98295",
   "metadata": {},
   "source": [
    "## Targeted Scenarios: Demonstrating Strategy Strengths\n",
    "\n",
    "**Notation (used throughout):**\n",
    "- $r_t$: daily return\n",
    "- $\\mu$: mean daily return\n",
    "- $\\sigma$: standard deviation of daily returns\n",
    "- Sharpe $= \\frac{\\mu}{\\sigma} \\sqrt{252}$\n",
    "- Tail-Adj Sharpe (CVaR95) $= \\frac{\\mu}{|\\mathrm{CVaR}_{0.95}|} \\sqrt{252}$\n",
    "\n",
    "We create 3 scenarios designed to show where each strategy excels:\n",
    "1. **Scenario A: MV_Simple wins** â€” stable regimes, low volatility variation\n",
    "2. **Scenario B: MV_CVaR wins** â€” rare but severe crashes (tail risk)\n",
    "3. **Scenario C: VolManagement wins** â€” strong volatility swings + regime flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a14c17-bcf3-4a17-8658-23bcec9342bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the results and test on 4 different test seeds / training seeds..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcdabb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# SCENARIO A: MV_SIMPLE WINS (stable / near-Gaussian / low tail value)\n",
    "# Why MV wins:\n",
    "# - risk is stable and tail asymmetry is minimal\n",
    "# - CVaR constraint adds little benefit; with a moderately high gamma in CVaR objective\n",
    "#   it tends to become unnecessarily conservative and slightly worse Sharpe\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "Q_stable = np.array([\n",
    "    [0.97, 0.02, 0.01],\n",
    "    [0.02, 0.96, 0.02],\n",
    "    [0.02, 0.03, 0.95],\n",
    "])\n",
    "\n",
    "# Means: Asset1 has higher mean across regimes, Asset2 slightly lower mean but safer.\n",
    "c_stable = np.array([\n",
    "    [0.0018, 0.0012],   # Bull\n",
    "    [0.0015, 0.0011],   # Neutral\n",
    "    [0.0012, 0.0010],   # Bear (still positive)\n",
    "])\n",
    "\n",
    "# Low vol across all regimes (little to time, little tail risk)\n",
    "Sigma_stable = np.array([\n",
    "    [[0.00050, 0.00010],\n",
    "     [0.00010, 0.00030]],\n",
    "    [[0.00055, 0.00010],\n",
    "     [0.00010, 0.00032]],\n",
    "    [[0.00060, 0.00010],\n",
    "     [0.00010, 0.00035]],\n",
    "])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# SCENARIO B: MV_CVaR WINS (rare-but-severe crash; MV underprices tail)\n",
    "# Why CVaR wins:\n",
    "# - Crash regime is rare (so MV still likes risky asset on average)\n",
    "# - But crash is severe for Asset1 -> worst months dominate tail metrics\n",
    "# - Bear is brief enough that lagged-vol timing is less reliable\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "Q_crash = np.array([\n",
    "    [0.992, 0.007, 0.001],  # Bear very rare\n",
    "    [0.060, 0.930, 0.010],\n",
    "    [0.200, 0.050, 0.750],  # Bear persistent (expected duration ~ 4 months)\n",
    "])\n",
    "\n",
    "c_crash = np.array([\n",
    "    [0.0030, 0.0010],     # Bull: Asset1 much better\n",
    "    [0.0010, 0.0008],\n",
    "    [-0.1500, 0.0003],    # Bear: extreme crash Asset1\n",
    "])\n",
    "\n",
    "Sigma_crash = np.array([\n",
    "    [[0.0006,  0.00010],\n",
    "     [0.00010, 0.00040]],\n",
    "    [[0.0012,  0.00020],\n",
    "     [0.00020, 0.00090]],\n",
    "    [[0.0600,  0.0040],   # Bear: very high vol, weak diversification\n",
    "     [0.0040,  0.0020]],\n",
    "])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# SCENARIO C: VOL MANAGEMENT WINS (big volatility swings + persistent high vol)\n",
    "# Why VolManagement wins:\n",
    "# - volatility changes a lot and is persistent\n",
    "# - high-vol regimes have lower Sharpe; scaling/tilting by lagged vol helps\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "Q_vol_regime = np.array([\n",
    "    [0.85, 0.10, 0.05],\n",
    "    [0.15, 0.70, 0.15],\n",
    "    [0.10, 0.15, 0.75],\n",
    "])\n",
    "\n",
    "c_vol_regime = np.array([\n",
    "    [0.0080, 0.0010],   # Bull: Asset1 dominates\n",
    "    [0.0030, 0.0030],   # Neutral\n",
    "    [-0.0040, 0.0060],  # Bear: Asset2 dominates\n",
    "])\n",
    "\n",
    "Sigma_vol_regime = np.array([\n",
    "    [[0.0002, 0.00003],\n",
    "     [0.00003, 0.0002]],\n",
    "    [[0.0015, 0.0003],\n",
    "     [0.0003, 0.0012]],\n",
    "    [[0.0100, 0.0020],\n",
    "     [0.0020, 0.0060]],\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa598e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seeds = [53, 274, 1234, 89]\n",
    "\n",
    "targeted_scenarios = [\n",
    "    (\"A_MV_Simple_Wins\", Q_stable,     c_stable,     Sigma_stable),\n",
    "    (\"B_MV_CVaR_Wins\",   Q_crash,      c_crash,      Sigma_crash),\n",
    "    (\"C_VolMgmt_Wins\",   Q_vol_regime, c_vol_regime, Sigma_vol_regime),\n",
    "]\n",
    "\n",
    "# tie tolerance for winner selection (prevents coin-flip when numbers are basically identical)\n",
    "TIE_EPS = 1e-6\n",
    "\n",
    "def choose_winner(metric_values: pd.Series, prefer: str | None = None, eps: float = 1e-6) -> str:\n",
    "    \"\"\"\n",
    "    Pick the winner, but if multiple are within eps of the max, optionally prefer a named strategy\n",
    "    (or fall back to alphabetical for determinism).\n",
    "    \"\"\"\n",
    "    maxv = float(metric_values.max())\n",
    "    close = metric_values[metric_values >= maxv - eps]\n",
    "    if len(close) == 1:\n",
    "        return close.index[0]\n",
    "    if prefer is not None and prefer in close.index:\n",
    "        return prefer\n",
    "    return sorted(close.index)[0]\n",
    "\n",
    "targeted_results = {}\n",
    "targeted_tables = {}\n",
    "\n",
    "for scenario_name, Q_matrix, c_scenario, Sigma_scenario in targeted_scenarios:\n",
    "\n",
    "    # CVaR settings (keep beta fixed for statistical meaning)\n",
    "    if scenario_name == \"A_MV_Simple_Wins\":\n",
    "        mv_cvar_beta = 0.95\n",
    "        mv_cvar_gamma = 1.0             # make CVaR \"over-care\" about tails in a stable world\n",
    "        winner_metric = \"Sharpe (ann.)\"\n",
    "        expected_winner = \"MV_Simple\"\n",
    "        tie_preference = \"MV_Simple\"     # if MV and CVaR are identical, interpret as \"MV wins / CVaR adds nothing\"\n",
    "    elif scenario_name == \"B_MV_CVaR_Wins\":\n",
    "        mv_cvar_beta = 0.95\n",
    "        mv_cvar_gamma = 1.0\n",
    "        winner_metric = \"Tail-Adj Sharpe (CVaR95)\"\n",
    "        expected_winner = \"MV_CVaR\"\n",
    "        tie_preference = \"MV_CVaR\"\n",
    "    else:\n",
    "        mv_cvar_beta = 0.95\n",
    "        mv_cvar_gamma = 1.0\n",
    "        winner_metric = \"Sharpe (ann.)\"\n",
    "        expected_winner = \"VolManagement\"\n",
    "        tie_preference = \"VolManagement\"\n",
    "\n",
    "    perf_tables = []\n",
    "    \n",
    "        \n",
    "    for seed in seeds:\n",
    "        env = MarkovSimulationEnvironment(\n",
    "            Q=Q_matrix,\n",
    "            c_list=c_scenario,\n",
    "            Phi=Phi_fixed,\n",
    "            Sigma_list=Sigma_scenario,\n",
    "            regime_names=regime_names,\n",
    "            T_days=252*70,\n",
    "            seed=seed,\n",
    "            burn_in_months=50,\n",
    "            start_date=\"2000-01-03\",\n",
    "            k0=0,\n",
    "            asset_names=[\"Asset1\", \"Asset2\"],\n",
    "            verbose=False\n",
    "        )\n",
    "        env.simulate()\n",
    "    \n",
    "        backtester = StrategyBacktester(env, verbose=False)\n",
    "        backtester.run_equal_weight(\"EqualWeight\")\n",
    "        backtester.run_mv_simple(\"MV_Simple\", gamma=5.0)\n",
    "        backtester.run_mw_cvar_simple(\"MV_CVaR\", beta=mv_cvar_beta, gamma=mv_cvar_gamma)\n",
    "        backtester.run_volatility_management(\"VolManagement\", gamma=5.0, c_tc=0.0021)\n",
    "        backtester.run_markowitz(\n",
    "            \"VolManagement_Unconditional\",\n",
    "            gamma=5.0,\n",
    "            c_tc=0.0021,\n",
    "            use_drift_turnover=True,\n",
    "            bounded_b=True\n",
    "        )\n",
    "    \n",
    "        portfolios = {name: data[\"monthly_returns\"] for name, data in backtester.results.items()}\n",
    "        perf_table = make_table_for_portfolios(portfolios, periods_per_year=12)\n",
    "        perf_tables.append(perf_table)\n",
    "    \n",
    "    # ---- Mean performance table across seeds ----\n",
    "    common_index = perf_tables[0].index\n",
    "    common_cols  = perf_tables[0].columns\n",
    "    perf_tables  = [t.reindex(index=common_index, columns=common_cols) for t in perf_tables]\n",
    "    \n",
    "    mean_table = sum(perf_tables) / len(perf_tables)\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 60)\n",
    "    print(f\"MEAN MONTHLY PERFORMANCE TABLE (across {len(seeds)} seeds): {scenario_name.replace('_',' ')}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(mean_table.round(3).to_string())\n",
    "    \n",
    "    # (Optional) choose winner ONCE from the averaged table\n",
    "    metric_values_mean = mean_table.loc[winner_metric]\n",
    "    winner_mean = choose_winner(metric_values_mean, prefer=tie_preference, eps=TIE_EPS)\n",
    "    print(f\"\\nWinner metric: {winner_metric}\")\n",
    "    print(f\"Winner on mean table: {winner_mean}\")\n",
    "    \n",
    "    targeted_results[scenario_name] = {\n",
    "        \"mean_perf_table\": mean_table,\n",
    "        \"winner_metric\": winner_metric,\n",
    "        \"winner_on_mean\": winner_mean,\n",
    "        \"seeds\": seeds,\n",
    "        \"mv_cvar_beta\": mv_cvar_beta,\n",
    "        \"mv_cvar_gamma\": mv_cvar_gamma,\n",
    "    }\n",
    "    targeted_tables[scenario_name] = mean_table\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
